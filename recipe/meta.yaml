{% set name = "ds-lime" %}
{% set version = "0.1.1.27" %}
{% set sha256 = "ee5a0002737e4d95800b1904f509c6e55498c97546c5ab449f9cded381f8b3bd" %}

package:
  name: {{ name|lower }}
  version: {{ version }}

source:
  fn: {{ name }}-{{ version }}.tar.gz
  url: https://pypi.io/packages/source/{{ name[0] }}/{{ name }}/{{ name }}-{{ version }}.tar.gz
  sha256: {{ sha256 }}

build:
  noarch: python
  number: 1
  script: python -m pip install --no-deps --ignore-installed .

requirements:
  host:
    - pip
    - python
    - setuptools
  run:
    - python
    - numpy
    - scipy
    - scikit-learn >=0.18

test:
  imports:
    - lime
    - lime.lime_text
    - lime.lime_tabular

about:
  home: https://github.com/datascienceinc/lime
  license: BSD-2-Clause
  license_family: BSD
  license_file: LICENSE
  summary: 'Local Interpretable Model-Agnostic Explanations (DataScience.com fork)'

  description: |
    This project is about explaining what machine learning classifiers
    (or models) are doing. At the moment, we support explaining individual
    predictions for text classifiers or classifiers that act on tables (numpy
    arrays of numerical or categorical data), with a package called lime
    (short for local interpretable model-agnostic explanations). This is the
    DataScience.com fork used in the Skater
    <https://github.com/datascienceinc/Skater> package.
  doc_url: https://marcotcr.github.io/lime/
  dev_url: https://github.com/datascienceinc/lime

extra:
  recipe-maintainers:
    - benvandyke
    - aikramer2
